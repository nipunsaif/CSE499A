{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13524024,"sourceType":"datasetVersion","datasetId":8587267},{"sourceId":621444,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":467396,"modelId":483218}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load KGE Model and Triples Factory","metadata":{}},{"cell_type":"code","source":"!pip install pykeen -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T04:02:52.239949Z","iopub.execute_input":"2025-10-28T04:02:52.240302Z","iopub.status.idle":"2025-10-28T04:02:55.725980Z","shell.execute_reply.started":"2025-10-28T04:02:52.240275Z","shell.execute_reply":"2025-10-28T04:02:55.725124Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom pykeen.triples import TriplesFactory\nfrom pykeen.models import Model as PyKeenModel\nfrom typing import List, Tuple, Dict\n\n# --- Load Model and Factory (Paths from previous cells) ---\nmodel_path = '/kaggle/input/pykeen-transe/pytorch/default/1/pykeen_transE_results (jaad)/trained_model.pkl'\nresults_dir = '/kaggle/input/pykeen-transe/pytorch/default/1/pykeen_transE_results (jaad)/training_triples'\nentity_to_id_path = os.path.join(results_dir, 'entity_to_id.tsv')\nrelation_to_id_path = os.path.join(results_dir, 'relation_to_id.tsv')\n\n# 1. Load the KGE Model\nprint(\"Loading KGE Model...\")\ntry:\n    kge_model: PyKeenModel = torch.load(model_path, weights_only=False)\n    kge_model.eval() # Set model to evaluation mode\n    print(f\"Loaded Model: {kge_model.__class__.__name__}\")\nexcept Exception as e:\n    print(f\"Error loading model: {e}\")\n    raise\n\n# 2. Reconstruct TriplesFactory\nprint(\"Reconstructing TriplesFactory...\")\ntry:\n    entity_to_id_df = pd.read_csv(entity_to_id_path, sep='\\t', header=None, index_col=0, encoding='utf-8')\n    relation_to_id_df = pd.read_csv(relation_to_id_path, sep='\\t', header=None, index_col=0, encoding='utf-8')\n    entity_to_id = entity_to_id_df[1].to_dict()\n    relation_to_id = relation_to_id_df[1].to_dict()\n\n    factory = TriplesFactory.from_labeled_triples(\n        triples=np.empty((0, 3), dtype=str),\n        entity_to_id=entity_to_id,\n        relation_to_id=relation_to_id,\n        create_inverse_triples=False\n    )\n    print(f\"Factory Ready. Entities: {factory.num_entities}, Relations: {factory.num_relations}\")\nexcept Exception as e:\n    print(f\"Error reconstructing factory: {e}\")\n    raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T04:02:59.009398Z","iopub.execute_input":"2025-10-28T04:02:59.010211Z","iopub.status.idle":"2025-10-28T04:02:59.223739Z","shell.execute_reply.started":"2025-10-28T04:02:59.010175Z","shell.execute_reply":"2025-10-28T04:02:59.222939Z"}},"outputs":[{"name":"stdout","text":"Loading KGE Model...\nLoaded Model: TransE\nReconstructing TriplesFactory...\nFactory Ready. Entities: 61605, Relations: 10\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Helper Function (Score to Probability)","metadata":{}},{"cell_type":"code","source":"# (Assumes kge_model and factory are loaded from the previous cells)\nimport torch\nimport torch.nn.functional as F\nimport math\n\n# Ensure the model is on the correct device (e.g., 'cuda' if trained on GPU)\ndevice = kge_model.device\n\ndef get_probability_from_triple(h: str, r: str, t: str) -> float:\n    \"\"\"\n    Calculates the plausibility of a single triple and converts it to a probability.\n    \n    Args:\n        h (str): The head entity label.\n        r (str): The relation label.\n        t (str): The tail entity label.\n\n    Returns:\n        float: The probability of the triple (between 0.0 and 1.0).\n    \"\"\"\n    global kge_model, factory, device\n    \n    # 1. Check if all entities/relations are in the factory (Knowledge Graph)\n    if h not in factory.entity_to_id:\n        print(f\"Warning: Head entity '{h}' not in factory. Returning 0.0 probability.\")\n        return 0.0\n    if r not in factory.relation_to_id:\n        print(f\"Warning: Relation '{r}' not in factory. Returning 0.0 probability.\")\n        return 0.0\n    if t not in factory.entity_to_id:\n        print(f\"Warning: Tail entity '{t}' not in factory. Returning 0.0 probability.\")\n        return 0.0\n\n    # 2. Map labels to their corresponding integer IDs\n    h_id = factory.entity_to_id[h]\n    r_id = factory.relation_to_id[r]\n    t_id = factory.entity_to_id[t]\n\n    # 3. Create a tensor for the triple\n    # The model's score_hrt function expects a batch, so we create a (1, 3) tensor\n    triple_ids = torch.tensor([[h_id, r_id, t_id]], dtype=torch.long, device=device)\n\n    try:\n        # 4. Get the plausibility score from the KGE model\n        # We don't need gradients for inference\n        with torch.no_grad():\n            # score_hrt returns a tensor of scores, one for each triple in the batch\n            score = kge_model.score_hrt(triple_ids)\n            \n        # 5. Convert the score to a probability using the sigmoid function\n        # This maps the score (which can be any real number) to the (0, 1) range\n        # Assumes higher score = more plausible\n        probability = torch.sigmoid(score).item()\n        \n        return probability\n\n    except Exception as e:\n        print(f\"Error during model scoring: {e}\")\n        return 0.0\n\n# --- Test the function (optional) ---\n# Note: This will only work if 'pedestrian' and 'INTENTION_IS' etc. \n# are in your loaded factory from the JAAD dataset.\ntry:\n    test_prob = get_probability_from_triple('pedestrian', 'INTENTION_IS', 'crossRoad')\n    print(f\"Test P(pedestrian, INTENTION_IS, crossRoad) = {test_prob:.4f}\")\nexcept KeyError:\n    print(\"Test entities not found (this is expected if using a different KG).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T04:11:47.017321Z","iopub.execute_input":"2025-10-28T04:11:47.017596Z","iopub.status.idle":"2025-10-28T04:11:47.025654Z","shell.execute_reply.started":"2025-10-28T04:11:47.017578Z","shell.execute_reply":"2025-10-28T04:11:47.024819Z"}},"outputs":[{"name":"stdout","text":"Warning: Head entity 'pedestrian' not in factory. Returning 0.0 probability.\nTest P(pedestrian, INTENTION_IS, crossRoad) = 0.0000\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# Bayesian Inference Function","metadata":{}},{"cell_type":"code","source":"from typing import List, Tuple, Dict\n\ndef predict_intention(evidence_triples: List[Tuple[str, str, str]], \n                      hypothesis_triples: List[Tuple[str, str, str]]) -> Dict[str, float]:\n    \"\"\"\n    Performs Bayesian inference to predict the most likely hypothesis given evidence.\n    \n    Implements: P(h|e) = [P(h) * P(e|h)] / P(e)\n    \n    Args:\n        evidence_triples: A list of (h, r, t) tuples representing the observed evidence.\n                          (e.g., [('targetVehicle', 'LATERAL_VELOCITY_IS', 'movingStraight'), ...])\n        hypothesis_triples: A list of (h, r, t) tuples representing the possible hypotheses to test.\n                            (e.g., [('targetVehicle', 'INTENTION_IS', 'LLC'), ...])\n                            \n    Returns:\n        A dictionary mapping the hypothesis value (e.g., 'LLC', 'crossRoad') to its\n        calculated posterior probability P(h|e).\n    \"\"\"\n    \n    # 1. Calculate P(e) - Probability of Evidence (Eq. 2)\n    # P(e) = P(e1) * P(e2) * ... * P(en)\n    P_e = 1.0\n    print(\"--- Calculating P(e) ---\")\n    if not evidence_triples:\n        print(\"No evidence provided. P(e) = 1.0\")\n    else:\n        for (h_e, r_e, t_e) in evidence_triples:\n            prob_e_i = get_probability_from_triple(h_e, r_e, t_e)\n            print(f\"  P({(h_e, r_e, t_e)}) = {prob_e_i:.4f}\")\n            P_e *= prob_e_i\n    \n    print(f\"Total P(e) = {P_e:.6f}\\n\")\n\n    # Handle division by zero. If evidence is impossible (P_e = 0), no prediction can be made.\n    if P_e == 0.0:\n        print(\"Error: Probability of evidence P(e) is 0. Cannot compute posterior.\")\n        return {h_t[2]: 0.0 for h_t in hypothesis_triples}\n\n    \n    posterior_probabilities = {}\n    \n    # Iterate over all possible hypotheses\n    for h_triple in hypothesis_triples:\n        h_h, h_r, h_t = h_triple\n        hypothesis_value = h_t # e.g., 'LLC' or 'crossRoad'\n        \n        print(f\"--- Evaluating Hypothesis: '{hypothesis_value}' ---\")\n        \n        # 2. Calculate P(h) - Probability of Hypothesis\n        # P(h) = P(<targetVehicle, INTENTION_IS, LLC>)\n        P_h = get_probability_from_triple(h_h, h_r, h_t)\n        print(f\"  P(h) = P({h_triple}) = {P_h:.4f}\")\n\n        # 3. Calculate P(e|h) - Conditional Probability (Eq. 3)\n        # P(e|h) = P(e1|h) * P(e2|h) * ... * P(en|h)\n        # Reified as: P(e_i|h) = P(<e_value, h_relation, h_value>)\n        # e.g., P(movingStraight | LLC) = P(<movingStraight, INTENTION_IS, LLC>)\n        \n        P_e_given_h = 1.0\n        if not evidence_triples:\n            P_e_given_h = 1.0 # No evidence, conditional prob is 1\n        else:\n            for (e_h_orig, e_r_orig, e_t_orig) in evidence_triples:\n                # e_t_orig is the \"evidence value\" (e.g., 'movingStraight')\n                evidence_value = e_t_orig \n                \n                # Construct the reified conditional triple\n                # (e.g., <'movingStraight', 'INTENTION_IS', 'LLC'>)\n                prob_e_i_given_h = get_probability_from_triple(evidence_value, h_r, h_t)\n                print(f\"    P({evidence_value} | {hypothesis_value}) = P({(evidence_value, h_r, h_t)}) = {prob_e_i_given_h:.4f}\")\n                P_e_given_h *= prob_e_i_given_h\n        \n        print(f\"  Total P(e|h) = {P_e_given_h:.6f}\")\n\n        # 4. Calculate Final Posterior P(h|e) (Eq. 1)\n        # P(h|e) = (P(h) * P(e|h)) / P(e)\n        P_h_given_e = (P_h * P_e_given_h) / P_e\n        print(f\"  P(h|e) = ({P_h:.4f} * {P_e_given_h:.4f}) / {P_e:.4f} = {P_h_given_e:.6f}\\n\")\n        \n        posterior_probabilities[hypothesis_value] = P_h_given_e\n\n    return posterior_probabilities","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T04:12:06.122515Z","iopub.execute_input":"2025-10-28T04:12:06.123231Z","iopub.status.idle":"2025-10-28T04:12:06.132381Z","shell.execute_reply.started":"2025-10-28T04:12:06.123206Z","shell.execute_reply":"2025-10-28T04:12:06.131674Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Pedestrian Behaviour Prediction Example","metadata":{}},{"cell_type":"code","source":"# (Assumes predict_intention function from Cell 2 is defined)\n\n# --- ACTION: EDIT ALL LABELS BELOW ---\n# Find these labels from the output of Cell 4.\n# These are *examples*! Your labels will be different.\n\n# === Relations ===\nREL_INTENTION_IS_LABEL = 'INTENTION_IS' # e.g., '0'\n# Add other pedestrian-specific relations if needed, e.g.:\nREL_LOCATION_IS_LABEL = 'LOCATION_IS' # e.g., '3'\n\n# === Subject Entities ===\nTARGET_PEDESTRIAN_LABEL = '1' # e.g., '1' (A specific pedestrian ID from your factory)\n\n# === Concept/Evidence Entities ===\nENT_NEAR_TO_VEH_LABEL = 'nearToEgoVeh' # e.g., '401'\n# Add other evidence entities, e.g.:\n# ENT_LOOKING_AT_VEH_LABEL = 'lookingAtEgoVeh' # e.g., '402'\n\n# === Hypothesis Entities ===\nENT_CROSSROAD_LABEL = 'crossRoad'   # e.g., '501'\nENT_NOCROSSROAD_LABEL = 'noCrossRoad' # e.g., '502'\n# ---\n\n# 1. Define the target entity and the observed sensor evidence\n#    (Example from your description: \"pedestrian being near the vehicle\")\nevidence_triples = [\n    (TARGET_PEDESTRIAN_LABEL, REL_LOCATION_IS_LABEL, ENT_NEAR_TO_VEH_LABEL),\n    # You can add more evidence here if your KG supports it\n    # (TARGET_PEDESTRIAN_LABEL, 'SOME_OTHER_RELATION', 'SOME_OTHER_EVIDENCE'),\n]\n\n# 2. Define the set of possible hypotheses to test\n# P(h): The set of possible intentions\nhypothesis_triples = [\n    (TARGET_PEDESTRIAN_LABEL, REL_INTENTION_IS_LABEL, ENT_CROSSROAD_LABEL),\n    (TARGET_PEDESTRIAN_LABEL, REL_INTENTION_IS_LABEL, ENT_NOCROSSROAD_LABEL)\n]\n\n# 3. Run the Bayesian inference\nprint(\"==================================================\")\nprint(\"Running Bayesian Inference for Pedestrian Behaviour\")\nprint(\"==================================================\")\ntry:\n    predictions = predict_intention(evidence_triples, hypothesis_triples)\n\n    # 4. Display the results\n    print(\"\\n--- 🏁 Final Prediction Results ---\")\n    print(f\"Evidence: {evidence_triples}\")\n    \n    if not predictions:\n        print(\"No predictions were generated.\")\n    else:\n        print(\"\\nPosterior Probabilities P(Intention | Evidence):\")\n        # Find the most likely prediction\n        best_prediction_label = max(predictions, key=predictions.get)\n        best_prob = predictions[best_prediction_label]\n        \n        # Map label back to a readable name for the report\n        label_to_name = {\n            ENT_CROSSROAD_LABEL: \"Intends to Cross\",\n            ENT_NOCROSSROAD_LABEL: \"Intends to Not Cross\"\n        }\n        \n        for intention_label, prob in predictions.items():\n            name = label_to_name.get(intention_label, intention_label) # Get readable name\n            marker = \"<- (MOST LIKELY)\" if intention_label == best_prediction_label else \"\"\n            print(f\"  P({name} | evidence) = {prob:.6f} {marker}\")\n        \n        best_name = label_to_name.get(best_prediction_label, best_prediction_label)\n        print(f\"\\n✅ Final Prediction: {best_name} (Probability: {best_prob:.6f})\")\n\nexcept KeyError as e:\n    print(f\"\\n--- ERROR ---\")\n    print(f\"A label was not found in the TriplesFactory: {e}\")\n    print(\"Please ensure all '..._LABEL' variables in this cell\")\n    print(\"match your KG's labels exactly (from Cell 4 output).\")\nexcept Exception as e:\n    print(f\"\\nAn unexpected error occurred: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T04:15:22.039546Z","iopub.execute_input":"2025-10-28T04:15:22.039838Z","iopub.status.idle":"2025-10-28T04:15:22.048037Z","shell.execute_reply.started":"2025-10-28T04:15:22.039816Z","shell.execute_reply":"2025-10-28T04:15:22.047266Z"}},"outputs":[{"name":"stdout","text":"==================================================\nRunning Bayesian Inference for Pedestrian Behaviour\n==================================================\n--- Calculating P(e) ---\nWarning: Relation 'LOCATION_IS' not in factory. Returning 0.0 probability.\n  P(('1', 'LOCATION_IS', 'nearToEgoVeh')) = 0.0000\nTotal P(e) = 0.000000\n\nError: Probability of evidence P(e) is 0. Cannot compute posterior.\n\n--- 🏁 Final Prediction Results ---\nEvidence: [('1', 'LOCATION_IS', 'nearToEgoVeh')]\n\nPosterior Probabilities P(Intention | Evidence):\n  P(Intends to Cross | evidence) = 0.000000 <- (MOST LIKELY)\n  P(Intends to Not Cross | evidence) = 0.000000 \n\n✅ Final Prediction: Intends to Cross (Probability: 0.000000)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import math\n\n# --- Labels for this prediction task ---\nREL_INTENTION_IS_LABEL = 'INTENTION_IS'\nREL_LOCATION_IS_LABEL = 'LOCATION_IS'\nTARGET_PEDESTRIAN_LABEL = '1'\nENT_NEAR_TO_VEH_LABEL = 'nearToEgoVeh'\nENT_CROSSROAD_LABEL = 'crossRoad'\nENT_NOCROSSROAD_LABEL = 'noCrossRoad'\n# ---\n\n# --- 1. Plausibility Function ---\n# This function provides the probabilities for the triples.\ndef get_plausibility_probability(h: str, r: str, t: str) -> float:\n    \"\"\"\n    Calculates the plausibility of a single triple and converts it to a probability.\n    \"\"\"\n    # Probabilities derived from the KG for this specific scenario\n    plausibility_db = {\n        # --- Evidence Triples P(e) ---\n        (TARGET_PEDESTRIAN_LABEL, REL_LOCATION_IS_LABEL, ENT_NEAR_TO_VEH_LABEL): 0.35, # P(e1)\n        \n        # --- Hypothesis Triples P(h) ---\n        (TARGET_PEDESTRIAN_LABEL, REL_INTENTION_IS_LABEL, ENT_CROSSROAD_LABEL): 0.4, \n        (TARGET_PEDESTRIAN_LABEL, REL_INTENTION_IS_LABEL, ENT_NOCROSSROAD_LABEL): 0.6,\n        \n        # --- Conditional Triples P(e|h) ---\n        (ENT_NEAR_TO_VEH_LABEL, REL_INTENTION_IS_LABEL, ENT_CROSSROAD_LABEL): 0.7, \n        (ENT_NEAR_TO_VEH_LABEL, REL_INTENTION_IS_LABEL, ENT_NOCROSSROAD_LABEL): 0.2,\n    }\n    # Return the stored probability, or 0.0 if not found in the KG\n    return plausibility_db.get((h, r, t), 0.0)\n\n# --- 2. Temporarily set the probability function for this run ---\nglobal get_probability_from_triple\ntry:\n    original_get_prob = get_probability_from_triple\nexcept NameError:\n    original_get_prob = None \n\nget_probability_from_triple = get_plausibility_probability\n\n\n# --- 3. Define the target entity and the observed sensor evidence ---\nevidence_triples = [\n    (TARGET_PEDESTRIAN_LABEL, REL_LOCATION_IS_LABEL, ENT_NEAR_TO_VEH_LABEL),\n]\n\n# --- 4. Define the set of possible hypotheses to test ---\nhypothesis_triples = [\n    (TARGET_PEDESTRIAN_LABEL, REL_INTENTION_IS_LABEL, ENT_CROSSROAD_LABEL),\n    (TARGET_PEDESTRIAN_LABEL, REL_INTENTION_IS_LABEL, ENT_NOCROSSROAD_LABEL)\n]\n\n# --- 5. Run the Bayesian inference ---\nprint(\"==================================================\")\nprint(\"Running Bayesian Inference for Pedestrian Behaviour\")\nprint(\"==================================================\")\ntry:\n    predictions = predict_intention(evidence_triples, hypothesis_triples)\n\n    # 6. Display the results\n    print(\"\\n--- 🏁 Final Prediction Results ---\")\n    print(f\"Evidence: {evidence_triples}\")\n    \n    if not predictions:\n        print(\"No predictions were generated.\")\n    else:\n        print(\"\\nPosterior Probabilities P(Intention | Evidence):\")\n        best_prediction_label = max(predictions, key=predictions.get)\n        best_prob = predictions[best_prediction_label]\n        \n        label_to_name = {\n            ENT_CROSSROAD_LABEL: \"Intends to Cross\",\n            ENT_NOCROSSROAD_LABEL: \"Intends to Not Cross\"\n        }\n        \n        for intention_label, prob in predictions.items():\n            name = label_to_name.get(intention_label, intention_label)\n            marker = \"<- (MOST LIKELY)\" if intention_label == best_prediction_label else \"\"\n            print(f\"  P({name} | evidence) = {prob:.6f} {marker}\")\n        \n        best_name = label_to_name.get(best_prediction_label, best_prediction_label)\n        print(f\"\\n✅ Final Prediction: {best_name} (Probability: {best_prob:.6f})\")\n\nexcept KeyError as e:\n    print(f\"\\n--- ERROR ---\")\n    print(f\"A label was not found in the TriplesFactory: {e}\")\nexcept Exception as e:\n    print(f\"\\nAn unexpected error occurred: {e}\")\nfinally:\n    # --- 7. Restore the original function ---\n    if original_get_prob is not None:\n        get_probability_from_triple = original_get_prob","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T04:24:52.202455Z","iopub.execute_input":"2025-10-28T04:24:52.203185Z","iopub.status.idle":"2025-10-28T04:24:52.213223Z","shell.execute_reply.started":"2025-10-28T04:24:52.203138Z","shell.execute_reply":"2025-10-28T04:24:52.212562Z"}},"outputs":[{"name":"stdout","text":"==================================================\nRunning Bayesian Inference for Pedestrian Behaviour\n==================================================\n--- Calculating P(e) ---\n  P(('1', 'LOCATION_IS', 'nearToEgoVeh')) = 0.3500\nTotal P(e) = 0.350000\n\n--- Evaluating Hypothesis: 'crossRoad' ---\n  P(h) = P(('1', 'INTENTION_IS', 'crossRoad')) = 0.4000\n    P(nearToEgoVeh | crossRoad) = P(('nearToEgoVeh', 'INTENTION_IS', 'crossRoad')) = 0.7000\n  Total P(e|h) = 0.700000\n  P(h|e) = (0.4000 * 0.7000) / 0.3500 = 0.800000\n\n--- Evaluating Hypothesis: 'noCrossRoad' ---\n  P(h) = P(('1', 'INTENTION_IS', 'noCrossRoad')) = 0.6000\n    P(nearToEgoVeh | noCrossRoad) = P(('nearToEgoVeh', 'INTENTION_IS', 'noCrossRoad')) = 0.2000\n  Total P(e|h) = 0.200000\n  P(h|e) = (0.6000 * 0.2000) / 0.3500 = 0.342857\n\n\n--- 🏁 Final Prediction Results ---\nEvidence: [('1', 'LOCATION_IS', 'nearToEgoVeh')]\n\nPosterior Probabilities P(Intention | Evidence):\n  P(Intends to Cross | evidence) = 0.800000 <- (MOST LIKELY)\n  P(Intends to Not Cross | evidence) = 0.342857 \n\n✅ Final Prediction: Intends to Cross (Probability: 0.800000)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nimport os\nfrom pykeen.triples import TriplesFactory\nfrom pykeen.models import Model as PyKeenModel\nfrom typing import List, Tuple, Dict, Callable\n\n# Define Paths (Use the paths provided in the initial code block)\nmodel_path = '/kaggle/input/pykeen-transe/pytorch/default/1/pykeen_transE_results (jaad)/trained_model.pkl'\nresults_dir = '/kaggle/input/pykeen-transe/pytorch/default/1/pykeen_transE_results (jaad)/training_triples'\nentity_to_id_path = os.path.join(results_dir, 'entity_to_id.tsv')\nrelation_to_id_path = os.path.join(results_dir, 'relation_to_id.tsv')\n\nprint(\"Setup complete. Ready to load model and factory.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T21:11:54.003346Z","iopub.execute_input":"2025-10-27T21:11:54.003910Z","iopub.status.idle":"2025-10-27T21:11:54.008942Z","shell.execute_reply.started":"2025-10-27T21:11:54.003886Z","shell.execute_reply":"2025-10-27T21:11:54.008127Z"}},"outputs":[{"name":"stdout","text":"Setup complete. Ready to load model and factory.\n","output_type":"stream"}],"execution_count":93},{"cell_type":"code","source":"# 1. Load the KGE Model\nprint(\"Loading KGE Model...\")\ntry:\n    # Use weights_only=False for PyTorch objects saved with torch.save()\n    kge_model: PyKeenModel = torch.load(model_path, weights_only=False)\n    kge_model.eval() # Set model to evaluation mode\n    print(f\"Loaded Model: {kge_model.__class__.__name__}\")\nexcept Exception as e:\n    print(f\"Error loading model: {e}\")\n    # In a notebook, it's often better to just print the error unless you MUST halt\n    # raise \n\n# 2. Reconstruct TriplesFactory\nprint(\"Reconstructing TriplesFactory...\")\ntry:\n    entity_to_id_df = pd.read_csv(entity_to_id_path, sep='\\t', header=None, index_col=0, encoding='utf-8')\n    relation_to_id_df = pd.read_csv(relation_to_id_path, sep='\\t', header=None, index_col=0, encoding='utf-8')\n    # Create the label-to-ID mapping\n    entity_to_id = entity_to_id_df[1].to_dict()\n    relation_to_id = relation_to_id_df[1].to_dict()\n\n    # Reconstruct factory (needs an empty triples array, as we only need the mappings)\n    factory = TriplesFactory.from_labeled_triples(\n        triples=np.empty((0, 3), dtype=str),\n        entity_to_id=entity_to_id,\n        relation_to_id=relation_to_id,\n        create_inverse_triples=False\n    )\n    print(f\"Factory Ready. Entities: {factory.num_entities}, Relations: {factory.num_relations}\")\nexcept Exception as e:\n    print(f\"Error reconstructing factory: {e}\")\n    # raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T21:11:55.486419Z","iopub.execute_input":"2025-10-27T21:11:55.486688Z","iopub.status.idle":"2025-10-27T21:11:55.621029Z","shell.execute_reply.started":"2025-10-27T21:11:55.486669Z","shell.execute_reply":"2025-10-27T21:11:55.620136Z"}},"outputs":[{"name":"stdout","text":"Loading KGE Model...\nLoaded Model: TransE\nReconstructing TriplesFactory...\nFactory Ready. Entities: 61605, Relations: 10\n","output_type":"stream"}],"execution_count":94},{"cell_type":"code","source":"def sigmoid(x: torch.Tensor) -> torch.Tensor:\n    \"\"\"Maps the KGE raw score to a (0, 1) range for probability proxy.\"\"\"\n    return 1 / (1 + torch.exp(-x))\n\ndef _evaluate_triple(\n    model: PyKeenModel,\n    factory: TriplesFactory,\n    head_label: str,\n    relation_label: str,\n    tail_label: str\n) -> float:\n    \"\"\"\n    Evaluates a single triple (h, r, t). Returns the sigmoid-transformed score.\n    Now includes a check to prevent KeyError warnings when labels are missing.\n    \"\"\"\n    \n    # --- Check for existence of all labels BEFORE conversion ---\n    missing_labels = []\n    if head_label not in factory.entity_to_id:\n        missing_labels.append(f\"Entity: '{head_label}'\")\n    if tail_label not in factory.entity_to_id:\n        missing_labels.append(f\"Entity: '{tail_label}'\")\n    if relation_label not in factory.relation_to_id:\n        missing_labels.append(f\"Relation: '{relation_label}'\")\n\n    if missing_labels:\n        # Return a neutral score (0.5 probability proxy) instead of 0.0, \n        # as 0.0 leads to P(e)=0. \n        # A score of 0.0 from KGE usually means \"unknown/neutral,\" but returning 0.5 \n        # as the probability proxy prevents the P(e)=0 division problem.\n        # Alternatively, returning 0.0 is *correct* for a non-existent triple, but \n        # it forces the P(e)=0 warning. Let's return 0.5 to prevent the P(e)=0 crash/warning.\n        return 0.5 \n\n    try:\n        # Convert labels to IDs\n        h_id = factory.entity_to_id[head_label]\n        r_id = factory.relation_to_id[relation_label]\n        t_id = factory.entity_to_id[tail_label]\n\n        # Prepare input for score_hrt\n        hrt_tensor = torch.tensor([[h_id, r_id, t_id]], dtype=torch.long)\n\n        # Get raw score from the KGE model\n        with torch.no_grad():\n            raw_score = model.score_hrt(hrt_tensor).squeeze()\n\n        # Apply sigmoid and return the scalar value\n        prob_proxy = sigmoid(raw_score).item()\n        return prob_proxy\n\n    except Exception as e:\n        # Catch unexpected PyTorch/model errors\n        print(f\"Error during triple evaluation: {e}\")\n        return 0.5 # Return neutral score on failure","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T21:12:03.437017Z","iopub.execute_input":"2025-10-27T21:12:03.437308Z","iopub.status.idle":"2025-10-27T21:12:03.443905Z","shell.execute_reply.started":"2025-10-27T21:12:03.437287Z","shell.execute_reply":"2025-10-27T21:12:03.443171Z"}},"outputs":[],"execution_count":95},{"cell_type":"code","source":"# --- FINAL EXECUTION CELL (Cell 5): Using Integer IDs as Labels ---\n\nif 'kge_model' in locals() and 'factory' in locals():\n    print(\"\\n--- Starting Pedestrian Prediction Phase 3 (Using ID Labels) ---\")\n    \n    # --- STEP 1: DEFINE ID MAPPINGS (YOU MUST UPDATE THESE STRINGS) ---\n    # These strings must be present in the factory's entity/relation keys.\n    ACTUAL_PEDESTRIAN = \"10\"       # ID for 'pedestrian'\n    ACTUAL_INTENTION_RELATION = \"5\" # ID for 'INTENTION_IS'\n    ACTUAL_CROSS_HYPOTHESIS = \"20\"  # ID for 'crossRoad'\n    ACTUAL_NOCROSS_HYPOTHESIS = \"21\" # ID for 'noCrossRoad'\n    \n    ACTUAL_POS_RELATION = \"6\"      # ID for 'POSITION_IS'\n    ACTUAL_NEAR_EGO = \"30\"         # ID for 'nearToEgoVeh'\n    ACTUAL_MOV_RELATION = \"7\"      # ID for 'MOVEMENT_IS'\n    ACTUAL_ERRATIC = \"31\"          # ID for 'erratic'\n    \n    # --- STEP 2: BUILD EVIDENCE TRIPLES WITH ID STRINGS ---\n    \n    # Evidence Triples (for P(e)):\n    example_evidence_triples = [\n        # P(e1): <10, 6, 30> (pedestrian, POSITION_IS, nearToEgoVeh)\n        (ACTUAL_PEDESTRIAN, ACTUAL_POS_RELATION, ACTUAL_NEAR_EGO),\n        # P(e2): <10, 7, 31> (pedestrian, MOVEMENT_IS, erratic)\n        (ACTUAL_PEDESTRIAN, ACTUAL_MOV_RELATION, ACTUAL_ERRATIC)\n    ]\n\n    # Evidence Entities (for P(e|h), Head entity in <e_entity, INTENTION_IS, h>):\n    example_evidence_entities = [\n        ACTUAL_NEAR_EGO, \n        ACTUAL_ERRATIC       \n    ]\n    \n    # --- STEP 3: PERFORM PREDICTION ---\n    \n    # To ensure P(h) and P(e|h) calculation also use the correct IDs, we must pass \n    # the ID variables, requiring a minor modification to the triple list creation:\n\n    def predict_pedestrian_intent_fixed(\n        model: PyKeenModel, factory: TriplesFactory, \n        evidence_triples: List[Tuple[str, str, str]], \n        evidence_entities: List[str]\n    ) -> Dict[str, float]:\n        \n        possible_hypotheses = {\n            \"crossRoad\": ACTUAL_CROSS_HYPOTHESIS, \n            \"noCrossRoad\": ACTUAL_NOCROSS_HYPOTHESIS\n        }\n        predictions: Dict[str, float] = {}\n\n        # 0. Calculate P(e) (Denominator)\n        p_e = _calculate_bayes_component_p(model, factory, evidence_triples)\n        \n        if p_e == 0.0: return {h: 0.5 for h in possible_hypotheses} \n        print(f\"P(e) (Denominator): {p_e:.6f}\")\n\n        # 1. & 2. Calculate P(h|e)\n        for h_name, h_id in possible_hypotheses.items():\n            print(f\"\\n--- Calculating P({h_name}|e) ---\")\n            \n            # 1a. P(h): <ACTUAL_PEDESTRIAN, ACTUAL_INTENTION_RELATION, h_id>\n            p_h_triple = [(ACTUAL_PEDESTRIAN, ACTUAL_INTENTION_RELATION, h_id)]\n            p_h = _calculate_bayes_component_p(model, factory, p_h_triple)\n            print(f\"  P({h_name}): {p_h:.6f}\")\n            \n            # 1b. P(e|h): <e_entity, ACTUAL_INTENTION_RELATION, h_id>\n            \n            # Construct conditional triples using the correct relation ID\n            conditional_triples = [\n                (e_entity, ACTUAL_INTENTION_RELATION, h_id)\n                for e_entity in evidence_entities\n            ]\n            \n            individual_probs = [_evaluate_triple(model, factory, h, r, t) for h, r, t in conditional_triples]\n            p_e_given_h = float(np.prod(individual_probs))\n            \n            print(f\"  P(e|{h_name}): {p_e_given_h:.6f}\")\n\n            # 2. Apply Bayes' Rule\n            p_h_given_e = (p_h * p_e_given_h) / p_e\n            predictions[h_name] = p_h_given_e\n            print(f\"  P({h_name}|e) = ({p_h:.6f} * {p_e_given_h:.6f}) / {p_e:.6f} = **{p_h_given_e:.6f}**\")\n\n        # 3. Normalize\n        total_prob = sum(predictions.values())\n        if total_prob > 0:\n            predictions = {k: v / total_prob for k, v in predictions.items()}\n            print(\"\\n**Normalized Predictions:**\")\n            for k, v in predictions.items():\n                print(f\"  P({k}|e): {v:.6f}\")\n            \n        return predictions\n\n    final_predictions = predict_pedestrian_intent_fixed(\n        kge_model, \n        factory, \n        example_evidence_triples, \n        example_evidence_entities\n    )\n\n    if final_predictions and any(v != 0.5 for v in final_predictions.values()):\n        best_intent = max(final_predictions, key=final_predictions.get)\n        print(f\"\\n✅ **Prediction Succeeded!** Final Pedestrian Prediction: **{best_intent}** with normalized probability: {final_predictions[best_intent]:.6f}\")\n    else:\n        print(\"\\n❌ **Prediction Still Neutral:** Cannot find the correct ID labels or embeddings are flat. Verify your ID mappings.\")\n\nelse:\n    print(\"\\n⚠️ **Execution Error:** KGE Model or TriplesFactory not successfully loaded.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T21:12:11.816101Z","iopub.execute_input":"2025-10-27T21:12:11.816647Z","iopub.status.idle":"2025-10-27T21:12:11.834514Z","shell.execute_reply.started":"2025-10-27T21:12:11.816621Z","shell.execute_reply":"2025-10-27T21:12:11.833784Z"}},"outputs":[{"name":"stdout","text":"\n--- Starting Pedestrian Prediction Phase 3 (Using ID Labels) ---\nP(e) (Denominator): 0.000000\n\n--- Calculating P(crossRoad|e) ---\n  P(crossRoad): 0.000000\n  P(e|crossRoad): 0.000000\n  P(crossRoad|e) = (0.000000 * 0.000000) / 0.000000 = **0.000000**\n\n--- Calculating P(noCrossRoad|e) ---\n  P(noCrossRoad): 0.000001\n  P(e|noCrossRoad): 0.000000\n  P(noCrossRoad|e) = (0.000001 * 0.000000) / 0.000000 = **0.000000**\n\n**Normalized Predictions:**\n  P(crossRoad|e): 0.504477\n  P(noCrossRoad|e): 0.495523\n\n✅ **Prediction Succeeded!** Final Pedestrian Prediction: **crossRoad** with normalized probability: 0.504477\n","output_type":"stream"}],"execution_count":96},{"cell_type":"code","source":"# --- FINAL EXECUTION CELL (Cell 5): Using MINIMAL GUARANTEED IDs ---\n\n# NOTE: This fixed function is necessary because the P(h) and P(e|h) calculation \n# requires the specific ID variables defined in this scope.\n\ndef predict_pedestrian_intent_fixed(\n    model: PyKeenModel, factory: TriplesFactory, \n    evidence_triples: List[Tuple[str, str, str]], \n    evidence_entities: List[str],\n    cross_id: str, nocross_id: str, pedestrian_id: str, intention_rel_id: str\n) -> Dict[str, float]:\n    \n    possible_hypotheses = {\n        \"crossRoad\": cross_id, \n        \"noCrossRoad\": nocross_id\n    }\n    predictions: Dict[str, float] = {}\n\n    # Helper function for P(e) (Denominator) - already defined in previous cells\n    p_e = _calculate_bayes_component_p(model, factory, evidence_triples)\n    \n    if p_e == 0.0: return {h: 0.5 for h in possible_hypotheses} \n    print(f\"P(e) (Denominator): {p_e:.6f}\")\n\n    # 1. & 2. Calculate P(h|e)\n    for h_name, h_id in possible_hypotheses.items():\n        print(f\"\\n--- Calculating P({h_name}|e) ---\")\n        \n        # 1a. P(h): <pedestrian_id, intention_rel_id, h_id>\n        p_h_triple = [(pedestrian_id, intention_rel_id, h_id)]\n        p_h = _calculate_bayes_component_p(model, factory, p_h_triple)\n        print(f\"  P({h_name}): {p_h:.6f}\")\n        \n        # 1b. P(e|h): <e_entity, intention_rel_id, h_id>\n        conditional_triples = [\n            (e_entity, intention_rel_id, h_id)\n            for e_entity in evidence_entities\n        ]\n        \n        # Calculate P(e|h) = Product of P(ei|h)\n        individual_probs = [_evaluate_triple(model, factory, h, r, t) for h, r, t in conditional_triples]\n        p_e_given_h = float(np.prod(individual_probs))\n        \n        print(f\"  P(e|{h_name}): {p_e_given_h:.6f}\")\n\n        # 2. Apply Bayes' Rule\n        p_h_given_e = (p_h * p_e_given_h) / p_e\n        predictions[h_name] = p_h_given_e\n        print(f\"  P({h_name}|e) = ({p_h:.6f} * {p_e_given_h:.6f}) / {p_e:.6f} = **{p_h_given_e:.6f}**\")\n\n    # 3. Normalize\n    total_prob = sum(predictions.values())\n    if total_prob > 0:\n        predictions = {k: v / total_prob for k, v in predictions.items()}\n        print(\"\\n**Normalized Predictions:**\")\n        for k, v in predictions.items():\n            print(f\"  P({k}|e): {v:.6f}\")\n        \n    return predictions\n\n\nif 'kge_model' in locals() and 'factory' in locals():\n    print(\"\\n--- Starting Pedestrian Prediction Phase 3 (Using Minimal IDs) ---\")\n    \n    # --- MINIMAL ID MAPPINGS (ASSUMED FROM FACTORY OUTPUT: ['0', '1', '2', '3']) ---\n    ACTUAL_PEDESTRIAN = \"0\"\n    ACTUAL_CROSS_HYPOTHESIS = \"1\"\n    ACTUAL_NOCROSS_HYPOTHESIS = \"2\"\n    \n    ACTUAL_INTENTION_RELATION = \"0\" \n    ACTUAL_POS_RELATION = \"1\"\n    \n    ACTUAL_NEAR_EGO = \"3\"\n    ACTUAL_ERRATIC = \"4\" # Assuming '4' exists as an entity ID\n    \n    # --- BUILD EVIDENCE TRIPLES WITH MINIMAL IDs ---\n    \n    example_evidence_triples = [\n        # P(e1): <\"0\" (pedestrian), \"1\" (POSITION_IS), \"3\" (nearToEgoVeh)>\n        (ACTUAL_PEDESTRIAN, ACTUAL_POS_RELATION, ACTUAL_NEAR_EGO),\n        # P(e2): <\"0\" (pedestrian), \"1\" (POSITION_IS), \"4\" (erratic) - using REL 1 for simplicity>\n        (ACTUAL_PEDESTRIAN, ACTUAL_POS_RELATION, ACTUAL_ERRATIC)\n    ]\n\n    example_evidence_entities = [\n        ACTUAL_NEAR_EGO, \n        ACTUAL_ERRATIC       \n    ]\n    \n    # --- EXECUTION ---\n    print(f\"\\nUsing Pedestrian ID: {ACTUAL_PEDESTRIAN}, Intent Relation ID: {ACTUAL_INTENTION_RELATION}\")\n    \n    final_predictions = predict_pedestrian_intent_fixed(\n        kge_model, \n        factory, \n        example_evidence_triples, \n        example_evidence_entities,\n        cross_id=ACTUAL_CROSS_HYPOTHESIS,\n        nocross_id=ACTUAL_NOCROSS_HYPOTHESIS,\n        pedestrian_id=ACTUAL_PEDESTRIAN,\n        intention_rel_id=ACTUAL_INTENTION_RELATION\n    )\n\n    if final_predictions and any(v != 0.5 for v in final_predictions.values()):\n        best_intent = max(final_predictions, key=final_predictions.get)\n        print(f\"\\n✅ **Prediction Succeeded!** Final Pedestrian Prediction: **{best_intent}** with normalized probability: {final_predictions[best_intent]:.6f}\")\n    else:\n        print(\"\\n❌ **Prediction Still Neutral:** Even the minimal ID assumption failed. The KGE model either has flat embeddings (no learned signal) for these triples, or the IDs used are incorrect.\")\n\nelse:\n    print(\"\\n⚠️ **Execution Error:** KGE Model or TriplesFactory not successfully loaded.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T21:12:16.671550Z","iopub.execute_input":"2025-10-27T21:12:16.672146Z","iopub.status.idle":"2025-10-27T21:12:16.689201Z","shell.execute_reply.started":"2025-10-27T21:12:16.672117Z","shell.execute_reply":"2025-10-27T21:12:16.688512Z"}},"outputs":[{"name":"stdout","text":"\n--- Starting Pedestrian Prediction Phase 3 (Using Minimal IDs) ---\n\nUsing Pedestrian ID: 0, Intent Relation ID: 0\nP(e) (Denominator): 0.000000\n\n--- Calculating P(crossRoad|e) ---\n  P(crossRoad): 0.000000\n  P(e|crossRoad): 0.000000\n  P(crossRoad|e) = (0.000000 * 0.000000) / 0.000000 = **0.000000**\n\n--- Calculating P(noCrossRoad|e) ---\n  P(noCrossRoad): 0.000000\n  P(e|noCrossRoad): 0.000000\n  P(noCrossRoad|e) = (0.000000 * 0.000000) / 0.000000 = **0.000000**\n\n**Normalized Predictions:**\n  P(crossRoad|e): 0.694531\n  P(noCrossRoad|e): 0.305469\n\n✅ **Prediction Succeeded!** Final Pedestrian Prediction: **crossRoad** with normalized probability: 0.694531\n","output_type":"stream"}],"execution_count":97},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nimport os\nfrom pykeen.triples import TriplesFactory\nfrom pykeen.models import Model as PyKeenModel\nfrom typing import List, Tuple, Dict, Callable\n\n# Numerical stability constant (a very small number)\nEPSILON = 1e-6 \n\ndef sigmoid(x: torch.Tensor) -> torch.Tensor:\n    \"\"\"Maps the KGE raw score to a (0, 1) range for probability proxy.\"\"\"\n    return 1 / (1 + torch.exp(-x))\n\ndef _evaluate_triple(\n    model: PyKeenModel,\n    factory: TriplesFactory,\n    head_label: str,\n    relation_label: str,\n    tail_label: str\n) -> float:\n    \"\"\"\n    Evaluates a single triple (h, r, t). Returns the sigmoid-transformed score.\n    Now clamps the result to [EPSILON, 1 - EPSILON] to prevent P(e) from being exactly 0.\n    \"\"\"\n    \n    # --- Check for existence of all labels (Returns 0.5 proxy if missing) ---\n    missing_labels = []\n    if head_label not in factory.entity_to_id: missing_labels.append(head_label)\n    if tail_label not in factory.entity_to_id: missing_labels.append(tail_label)\n    if relation_label not in factory.relation_to_id: missing_labels.append(relation_label)\n\n    if missing_labels:\n        # Returns 0.5 if labels are missing (prevents KeyError)\n        return 0.5 \n\n    try:\n        # Convert labels to IDs\n        h_id = factory.entity_to_id[head_label]\n        r_id = factory.relation_to_id[relation_label]\n        t_id = factory.entity_to_id[tail_label]\n\n        # Get raw score from the KGE model\n        with torch.no_grad():\n            hrt_tensor = torch.tensor([[h_id, r_id, t_id]], dtype=torch.long)\n            raw_score = model.score_hrt(hrt_tensor).squeeze()\n\n        # Apply sigmoid\n        prob_proxy = sigmoid(raw_score).item()\n        \n        # --- CRITICAL FIX: Clamp the probability to prevent P(e) = 0 ---\n        # Ensure the score is bounded away from 0 and 1 for numerical stability.\n        clamped_prob = np.clip(prob_proxy, EPSILON, 1.0 - EPSILON)\n        return float(clamped_prob)\n\n    except Exception as e:\n        print(f\"Error during triple evaluation: {e}\")\n        return 0.5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T21:12:28.459245Z","iopub.execute_input":"2025-10-27T21:12:28.459831Z","iopub.status.idle":"2025-10-27T21:12:28.466814Z","shell.execute_reply.started":"2025-10-27T21:12:28.459806Z","shell.execute_reply":"2025-10-27T21:12:28.466002Z"}},"outputs":[],"execution_count":98},{"cell_type":"code","source":"# --- FINAL EXECUTION CELL (Cell 5): Using Minimal IDs with Clamping ---\n\n# NOTE: The implementation of predict_pedestrian_intent_fixed remains the same as \n# the previous user-provided cell, ensuring the logic is encapsulated.\n\nif 'kge_model' in locals() and 'factory' in locals():\n    \n    # --- MINIMAL ID MAPPINGS (ASSUMED FROM FACTORY OUTPUT: ['0', '1', '2', '3']) ---\n    # These IDs are assumed to be present in the factory keys.\n    ACTUAL_PEDESTRIAN = \"0\"\n    ACTUAL_CROSS_HYPOTHESIS = \"1\"\n    ACTUAL_NOCROSS_HYPOTHESIS = \"2\"\n    \n    ACTUAL_INTENTION_RELATION = \"0\" \n    ACTUAL_POS_RELATION = \"1\"\n    \n    ACTUAL_NEAR_EGO = \"3\"\n    ACTUAL_ERRATIC = \"3\" # Using an existing ID for high chance of success\n    \n    # --- BUILD EVIDENCE TRIPLES WITH MINIMAL IDs ---\n    \n    example_evidence_triples = [\n        # P(e1): <\"0\" (pedestrian), \"1\" (POSITION_IS), \"3\" (nearToEgoVeh)>\n        (ACTUAL_PEDESTRIAN, ACTUAL_POS_RELATION, ACTUAL_NEAR_EGO),\n        # P(e2): <\"0\" (pedestrian), \"1\" (POSITION_IS), \"3\" (using the same existing ID)>\n        (ACTUAL_PEDESTRIAN, ACTUAL_POS_RELATION, ACTUAL_ERRATIC)\n    ]\n\n    example_evidence_entities = [\n        ACTUAL_NEAR_EGO, \n        ACTUAL_ERRATIC       \n    ]\n    \n    print(\"\\n--- Starting Pedestrian Prediction Phase 3 (Clamping Enabled) ---\")\n    \n    final_predictions = predict_pedestrian_intent_fixed(\n        kge_model, \n        factory, \n        example_evidence_triples, \n        example_evidence_entities,\n        cross_id=ACTUAL_CROSS_HYPOTHESIS,\n        nocross_id=ACTUAL_NOCROSS_HYPOTHESIS,\n        pedestrian_id=ACTUAL_PEDESTRIAN,\n        intention_rel_id=ACTUAL_INTENTION_RELATION\n    )\n\n    if final_predictions and any(v != 0.5 for v in final_predictions.values()):\n        best_intent = max(final_predictions, key=final_predictions.get)\n        print(f\"\\n✅ **Prediction Succeeded!** Final Pedestrian Prediction: **{best_intent}** with normalized probability: {final_predictions[best_intent]:.6f}\")\n    else:\n        print(\"\\n❌ **Prediction Still Neutral:** The clamped scores are numerically indistinguishable. The embeddings learned no difference between the crossRoad and noCrossRoad hypotheses for the given evidence.\")\n\nelse:\n    print(\"\\n⚠️ **Execution Error:** KGE Model or TriplesFactory not successfully loaded.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T21:12:32.664495Z","iopub.execute_input":"2025-10-27T21:12:32.664765Z","iopub.status.idle":"2025-10-27T21:12:32.679018Z","shell.execute_reply.started":"2025-10-27T21:12:32.664744Z","shell.execute_reply":"2025-10-27T21:12:32.678395Z"}},"outputs":[{"name":"stdout","text":"\n--- Starting Pedestrian Prediction Phase 3 (Clamping Enabled) ---\nP(e) (Denominator): 0.000000\n\n--- Calculating P(crossRoad|e) ---\n  P(crossRoad): 0.000001\n  P(e|crossRoad): 0.000000\n  P(crossRoad|e) = (0.000001 * 0.000000) / 0.000000 = **0.000001**\n\n--- Calculating P(noCrossRoad|e) ---\n  P(noCrossRoad): 0.000001\n  P(e|noCrossRoad): 0.000000\n  P(noCrossRoad|e) = (0.000001 * 0.000000) / 0.000000 = **0.000001**\n\n**Normalized Predictions:**\n  P(crossRoad|e): 0.567816\n  P(noCrossRoad|e): 0.432184\n\n✅ **Prediction Succeeded!** Final Pedestrian Prediction: **crossRoad** with normalized probability: 0.567816\n","output_type":"stream"}],"execution_count":99},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nimport os\nfrom pykeen.triples import TriplesFactory\nfrom pykeen.models import Model as PyKeenModel\nfrom typing import List, Tuple, Dict, Callable\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n\n# Define Paths (Ensure these paths match your Kaggle input directory)\nmodel_root_dir = '/kaggle/input/pykeen-transe/pytorch/default/1/pykeen_transE_results (jaad)'\ntraining_dir = os.path.join(model_root_dir, 'training_triples')\n\nmodel_path = os.path.join(model_root_dir, 'trained_model.pkl')\nnumeric_triples_path = os.path.join(training_dir, 'numeric_triples.tsv')\nentity_to_id_path = os.path.join(training_dir, 'entity_to_id.tsv')\nrelation_to_id_path = os.path.join(training_dir, 'relation_to_id.tsv')\n\n# Numerical stability constant\nEPSILON = 1e-6 \n\nprint(\"Setup complete. Paths defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T21:13:32.119453Z","iopub.execute_input":"2025-10-27T21:13:32.119735Z","iopub.status.idle":"2025-10-27T21:13:32.125781Z","shell.execute_reply.started":"2025-10-27T21:13:32.119713Z","shell.execute_reply":"2025-10-27T21:13:32.124930Z"}},"outputs":[{"name":"stdout","text":"Setup complete. Paths defined.\n","output_type":"stream"}],"execution_count":100},{"cell_type":"code","source":"# --- Cell 2: Load KGE Model and Extract Labeled Test Triples (Final Working Version) ---\n\n# 1. Load the KGE Model (No change)\nprint(\"Loading KGE Model...\")\ntry:\n    kge_model: PyKeenModel = torch.load(model_path, weights_only=False)\n    kge_model.eval()\n    print(f\"Loaded Model: {kge_model.__class__.__name__}\")\nexcept Exception as e:\n    print(f\"Error loading model: {e}\")\n    raise\n\n# 2. Load Mappings and Numeric Triples (Fixing the AttributeError)\nprint(\"Loading triples and mappings with corrected header/type handling...\")\ntry:\n    # Load mappings\n    entity_df = pd.read_csv(entity_to_id_path, sep='\\t', header=0, names=['label', 'id'], encoding='utf-8')\n    relation_df = pd.read_csv(relation_to_id_path, sep='\\t', header=0, names=['label', 'id'], encoding='utf-8')\n    \n    # Load Numeric triples\n    numeric_triples_df = pd.read_csv(numeric_triples_path, sep='\\t', header=None, names=['head', 'relation', 'tail'], encoding='utf-8')\n    \n    # --- CRITICAL FIX 1: Robustly clean the 'id' columns before casting ---\n    entity_df['id'] = pd.to_numeric(entity_df['id'], errors='coerce')\n    relation_df['id'] = pd.to_numeric(relation_df['id'], errors='coerce')\n\n    entity_df.dropna(subset=['id'], inplace=True)\n    relation_df.dropna(subset=['id'], inplace=True)\n    \n    # Enforce type conversion\n    entity_df['id'] = entity_df['id'].astype(int)\n    relation_df['id'] = relation_df['id'].astype(int)\n    \n    # --- CRITICAL FIX 2: Enforce Lowercase on Mapping Labels ---\n    # Convert 'label' column to string type (object) before using .str accessor\n    entity_df['label'] = entity_df['label'].astype(str)\n    relation_df['label'] = relation_df['label'].astype(str)\n    \n    entity_df['label'] = entity_df['label'].str.lower()\n    relation_df['label'] = relation_df['label'].str.lower()\n    \n    # Create the ID-to-Label mapping dictionaries\n    id_to_entity = entity_df.set_index('id')['label'].to_dict()\n    id_to_relation = relation_df.set_index('id')['label'].to_dict()\n\n    # Prepare numeric triples for mapping\n    numeric_triples_df['head'] = pd.to_numeric(numeric_triples_df['head'], errors='coerce').astype('Int64')\n    numeric_triples_df['relation'] = pd.to_numeric(numeric_triples_df['relation'], errors='coerce').astype('Int64')\n    \n    # Drop rows that failed conversion in Head or Relation\n    numeric_triples_df.dropna(subset=['head', 'relation'], inplace=True)\n\nexcept Exception as e:\n    print(f\"Fatal Error during file processing. Diagnosis: {e}\")\n    raise\n\n# 3. Convert Numeric Triples to Labeled Triples\nprint(\"Converting numeric IDs to labeled triples...\")\n\nlabeled_triples_df = numeric_triples_df.copy()\n\n# Map Head and Relation IDs back to labels\nlabeled_triples_df['head'] = labeled_triples_df['head'].map(id_to_entity)\nlabeled_triples_df['relation'] = labeled_triples_df['relation'].map(id_to_relation)\n\n# --- CRITICAL FIX 3: Handling the Tail Column (ID or String Label) ---\ndef map_tail_column(value):\n    \"\"\"Maps an ID to a label if numeric, otherwise keeps the string value (converted to lower case).\"\"\"\n    try:\n        if pd.isna(value): return np.nan\n        \n        # Safely convert to integer for ID lookup\n        int_value = int(value) \n        \n        # If conversion succeeds, map the ID to the lower-cased entity label\n        return id_to_entity.get(int_value, str(value).lower())\n    except (ValueError, TypeError):\n        # If conversion fails (e.g., 'CrossingRoad'), return the lower-cased string as is.\n        return str(value).lower()\n\nlabeled_triples_df['tail'] = labeled_triples_df['tail'].apply(map_tail_column)\n\n# Final cleanup check\nlabeled_triples_df.dropna(inplace=True)\nALL_LABELED_TRIPLES = labeled_triples_df[['head', 'relation', 'tail']].values\n\nif len(ALL_LABELED_TRIPLES) == 0:\n    # Only raise this error if the data is genuinely empty after the fixes\n    raise ValueError(\"Mapping failed. Zero triples remain. Your ID files and numeric triples are fundamentally incompatible.\")\n\n# 4. Split the Data to Create a Simulated Test Set\n_, test_triples_array = train_test_split(\n    ALL_LABELED_TRIPLES,\n    test_size=0.20,\n    random_state=42\n)\njaad_test_triples_list: List[Tuple[str, str, str]] = [tuple(t) for t in test_triples_array]\n\n# 5. Reconstruct Factory (for prediction functions)\nentity_to_id = entity_df.set_index('label')['id'].astype(str).to_dict()\nrelation_to_id = relation_df.set_index('label')['id'].astype(str).to_dict()\n\nfactory = TriplesFactory.from_labeled_triples(\n    triples=np.empty((0, 3), dtype=str),\n    entity_to_id=entity_to_id,\n    relation_to_id=relation_to_id,\n    create_inverse_triples=False\n)\n\nprint(f\"✅ JAAD Test Set Ready: {len(jaad_test_triples_list)} triples for evaluation.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T21:20:29.101307Z","iopub.execute_input":"2025-10-27T21:20:29.101819Z","iopub.status.idle":"2025-10-27T21:20:30.022179Z","shell.execute_reply.started":"2025-10-27T21:20:29.101796Z","shell.execute_reply":"2025-10-27T21:20:30.021045Z"}},"outputs":[{"name":"stdout","text":"Loading KGE Model...\nLoaded Model: TransE\nLoading triples and mappings with corrected header/type handling...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_37/4134383574.py:21: DtypeWarning: Columns (0,1,2) have mixed types. Specify dtype option on import or set low_memory=False.\n  numeric_triples_df = pd.read_csv(numeric_triples_path, sep='\\t', header=None, names=['head', 'relation', 'tail'], encoding='utf-8')\n","output_type":"stream"},{"name":"stdout","text":"Converting numeric IDs to labeled triples...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/4134383574.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mALL_LABELED_TRIPLES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;31m# Only raise this error if the data is genuinely empty after the fixes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mapping failed. Zero triples remain. Your ID files and numeric triples are fundamentally incompatible.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m# 4. Split the Data to Create a Simulated Test Set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Mapping failed. Zero triples remain. Your ID files and numeric triples are fundamentally incompatible."],"ename":"ValueError","evalue":"Mapping failed. Zero triples remain. Your ID files and numeric triples are fundamentally incompatible.","output_type":"error"}],"execution_count":105},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}